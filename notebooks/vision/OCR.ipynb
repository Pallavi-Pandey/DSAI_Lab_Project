{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForCausalLM, AutoProcessor, AutoConfig\n",
        "import torch\n",
        "from PIL import Image\n",
        "import requests"
      ],
      "metadata": {
        "id": "ImmEVSTjkP6G"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aOoCX1KikLnh",
        "outputId": "bb93a44d-5f36-46f4-92dc-64af1953e470"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dear User,Handwrytten uses robotichandwriting machines that usean actual pen to write yourmessage. The results are verticallyindistinguishable from actualhandworthing.Try it today!The Robot\n"
          ]
        }
      ],
      "source": [
        "from io import BytesIO\n",
        "\n",
        "\n",
        "# Device setup\n",
        "device = \"cuda\"\n",
        "\n",
        "# Load Florence-2 model and processor\n",
        "model_name = \"gokaygokay/Florence-2-Flux-Large\"\n",
        "model = AutoModelForCausalLM.from_pretrained(\"gokaygokay/Florence-2-Flux-Large\", trust_remote_code=True).to(device).eval()\n",
        "processor = AutoProcessor.from_pretrained(model_name, trust_remote_code=True)\n",
        "\n",
        "# Function to perform OCR using Florence-2\n",
        "def run_ocr(image):\n",
        "    task_prompt = \"<OCR>\"\n",
        "\n",
        "    # Ensure the image is in RGB mode\n",
        "    if image.mode != \"RGB\":\n",
        "        image = image.convert(\"RGB\")\n",
        "\n",
        "    inputs = processor(text=task_prompt, images=image, return_tensors=\"pt\").to(device)\n",
        "    generated_ids = model.generate(\n",
        "        input_ids=inputs[\"input_ids\"],\n",
        "        pixel_values=inputs[\"pixel_values\"],\n",
        "        max_new_tokens=512,  # OCR output is usually shorter\n",
        "        num_beams=3,\n",
        "        repetition_penalty=1.10,\n",
        "    )\n",
        "    generated_text = processor.batch_decode(generated_ids, skip_special_tokens=False)[0]\n",
        "    parsed_answer = processor.post_process_generation(generated_text, task=task_prompt, image_size=(image.width, image.height))\n",
        "    return parsed_answer[\"<OCR>\"]\n",
        "\n",
        "# Load image\n",
        "image_url = \"https://raw.githubusercontent.com/gokul-1998/handwriting_recognition/main/test_images/test3.png\"\n",
        "response = requests.get(image_url)\n",
        "image = Image.open(BytesIO(response.content))\n",
        "\n",
        "\n",
        "# Perform OCR\n",
        "ocr_text = run_ocr(image)\n",
        "print(ocr_text)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "HdBC_Orom24a"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}